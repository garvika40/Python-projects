# -*- coding: utf-8 -*-
"""Testing_of_library.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fneuT44n40yBFjapHhuj3Y2JOzmwlRqG

#Module_1
##Read_data
"""

pip install -i https://test.pypi.org/simple/ dastats

from published.Read_data import read_csv, head, tail, view_complete_data
data='/content/sample_data/california_housing_train.csv'
col_names, rows = read_csv(data)
# head(data)
# tail(data)
col_names

"""#Module_2

##Descriptive_Statistics
"""

from published.Descriptive_statistics import *
print(f"mean of {col_names[0]}",mean(rows[0]))
print(f"median of {col_names[1]}",median(rows[1]))
print(f"variance of {col_names[3]}", variance(rows[3]))
print(f"standard deviation of {col_names[3]}", standard_deviation(rows[3]))
print(f"mode of {col_names[4]}",mode)
print(f"summary statistic for {col_names[1]}",summary_statistics(rows[1]))
print(f"quantiles of {col_names[2]}",quantiles(rows[3]))

#comparison

import numpy as np
mn=np.mean(rows[0])
print(mn)
var=np.var(rows[3])
print(var)

"""#Module_3

##Correlation_test
"""

from published.Correlation import *
print(f"pearsons_corr_coeff for {col_names[0]} and {col_names[1]}:",pearson_correlation(rows[0],rows[1]))
print(f"spearman_rank_corr_coeff for {col_names[0]} and {col_names[1]}:",spearman_rank_correlation(rows[0],rows[1]))
print(f"kendall_rank_corr_coeff for {col_names[0]} and {col_names[1]}:",kendalls_rank_correlation(rows[0],rows[1]))

#comparison

from scipy.stats import spearmanr
scr=spearmanr(rows[0],rows[1])
print(scr)

"""#Module_4

##Hypothesis_testing
"""

from published.Hypothesis_testing import *
print(f"Independent t test statistic for {col_names[2]} and {col_names[3]}:",ttest_ind(rows[2],rows[3]))
print("\n")
print(f"Paired t test statistic for {col_names[2]} and {col_names[3]}:",ttest_rel(rows[2],rows[3]))
print("\n")
print(f"Annova test statistic for {col_names[2]} and {col_names[3]}:",annova(rows[2],rows[3]))

#comparison

from scipy.stats import ttest_ind
tind=ttest_ind(rows[2],rows[3])
print(tind)

"""#Module_5

##Test_Type



"""

from published.Parametric_dist import *
parametric_test(rows[3])
nonparametric_test(rows[3])



"""#Module_6

##Non_Parametric_tests
"""

from published.Non_parametric_tests import *
print(f"mann_whitney_u_test coeff for {col_names[0] and col_names[1]}: {mann_whitney_u_test(rows[0],rows[1])}")
print(f"wilcoxon_signed_rank_test coeff for {col_names[1] and col_names[1]}: {wilcoxon_signed_rank_test(rows[0],rows[1])}")
print(f"friedman_test coeff {col_names[0] and col_names[1]}:",{friedman_test(rows[0],rows[1])})

#comparison

from scipy.stats import mannwhitneyu
manwh=mannwhitneyu(rows[0],rows[1])
print(manwh)

#The Mann-Whitney U test may behave differently in the presence of ties (i.e., when there are identical values in the data). Depending on the software or library you are using, tie-handling methods may differ.

"""## Module_7"""

from published.Normality import *

klm=kolmogorov_smirnov_test(rows[3],distribution='normal')
print(f"Kolmogorov smirnov test statistic and p value for {col_names[3]}")
print(klm)

shp_wlk=shapiro_wilk_test(rows[3])
print(f"shapiro wilk test statistic and p value for {col_names[3]}")
print(shp_wlk)

from scipy.stats import shapiro
shp=shapiro(rows[3])
print(shp)

"""## MODULE 8"""

from published.Regression_analysis import *

data='/content/sample_data/california_housing_train.csv'

intercept, slope = linear_regression_fit(rows[4], rows[5])

print(f"linear regression coeff for {col_names[4]} and {col_names[5]}")
print("Intercept:", intercept)
print("Slope:", slope)

#comparison

from scipy.stats import linregress
lin_rgs=linregress(rows[4],rows[5])
print(lin_rgs)

kpss=kpss_test(rows[4])

print(f"kpss test statistic for {col_names[4]}")
print('result_statistic:',kpss)

adf=adf_test(rows[5])
print(f"adf test statistic for {col_names[5]}")
print('result_statistic:',adf)

mse=calculate_mse(rows[4],rows[5])
print(f"mse for {col_names[4]}")
print(mse)

rmse=calculate_rmse(rows[4],rows[5])
print(f"rmse for {col_names[4]}")
print(rmse)

#comparison

from sklearn.metrics import mean_squared_error
mse=mean_squared_error(rows[4],rows[5])
print(mse)

r_sq=calculate_r_squared(rows[6],rows[7])
print(f"r_squared (coefficient) for {col_names[4]}")
print(rmse)

